{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "['fundamentals.csv', 'prices-split-adjusted.csv', 'prices.csv', 'securities.csv']\n"
     ]
    }
   ],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load in \n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the \"../input/\" directory.\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n",
    "\n",
    "import os\n",
    "print(os.listdir(\"input/\"))\n",
    "\n",
    "# Any results you write to the current directory are saved as output."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
    "collapsed": true
   },
   "source": [
    "# using SVM to predict if a stock will rise based on previous information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "_cell_guid": "8c7e5205-e88c-4d2d-816a-97afe2db0666",
    "_uuid": "7a71c75c26b03ad61c9e438f6c6d657d0e39c45d"
   },
   "outputs": [],
   "source": [
    "#using svm to predict stock\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import svm,preprocessing \n",
    "from sklearn.metrics import classification_report\n",
    "stock_prices = pd.read_csv(r'input/prices.csv')\n",
    "symbols = list(set(stock_prices['symbol']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "_cell_guid": "0a58ab3d-5717-484a-b2df-9db6eb6649ce",
    "_kg_hide-output": true,
    "_uuid": "42ce17a9ea14d8a0c2962d22f5edabf7c0b4dcd9"
   },
   "outputs": [],
   "source": [
    "msft_prices = stock_prices[stock_prices['symbol']== 'MSFT']\n",
    "msft_prices = msft_prices[['date','open','low','high','close','volume']]\n",
    "msft_prices.to_csv('msft_prices.csv',sep='\\t')\n",
    "msft_dates = [pd.Timestamp(date) for date in msft_prices['date']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "_cell_guid": "2526237d-4625-480f-bdd2-26a1d402de0d",
    "_uuid": "dd3dd61ab9aaf04a37ce0b63b50962b2ba171038"
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<Figure size 640x480 with 1 Axes>"
     },
     "metadata": {}
    }
   ],
   "source": [
    "msft_close = np.array(msft_prices['close'],dtype='float')\n",
    "import matplotlib.pyplot as plt\n",
    "plt.title('MSFT')\n",
    "plt.scatter(msft_dates,msft_close)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "_cell_guid": "6a2c2278-ac94-453f-adc3-7a5dd6895d43",
    "_uuid": "aaf6b6e477336c7911d214c54c9cb360146d39fb"
   },
   "outputs": [],
   "source": [
    "msft_prices = msft_prices.set_index('date')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "_cell_guid": "8bba5e99-6aa4-427b-8589-b0c525cce393",
    "_uuid": "a4205f903e5dedb22846e746123553905935a67c"
   },
   "outputs": [],
   "source": [
    "def get_x_and_y(price,window_length=7,predict_day_length=1):\n",
    "    '''get train and test set\n",
    "    every time get window from price and\n",
    "    '''\n",
    "    m = len(price.iloc[0])\n",
    "    n = len(price) - window_length\n",
    "    m = window_length * m\n",
    "\n",
    "    x = np.ones((n,m))\n",
    "    y = np.ones((n,1))\n",
    "\n",
    "    for i in range(len(price)-window_length):\n",
    "        ans = [list(price.iloc[j] for j in range(i,i+window_length))]\n",
    "        ans = np.array(ans).flatten()\n",
    "        x[i] = ans\n",
    "        y[i] = 1 if price.close[i+window_length+predict_day_length-1] - price.close[i+window_length-1] >0 else 0\n",
    "    return [x,y]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "_cell_guid": "324ea949-55c7-48c5-a61a-0713fe3996c2",
    "_uuid": "3444fa38ee48bc872c3573b77e0469aad45e9137"
   },
   "outputs": [],
   "source": [
    "def train_and_test(price,window_length,accurarys,reports):\n",
    "    x,y = get_x_and_y(msft_prices,window_length=window_length)\n",
    "    y = y.flatten()\n",
    "    scaler = preprocessing.StandardScaler()\n",
    "    scaler.fit_transform(x)\n",
    "    x_train,x_test,y_train,y_test = train_test_split(x,y,test_size=0.25,random_state=233)\n",
    "    for kernel_arg in ['rbf','poly','linear']:\n",
    "        clf = svm.SVC(kernel=kernel_arg,max_iter=5000)\n",
    "        clf.fit(x_train,y_train)\n",
    "        y_predict = clf.predict(x_test)\n",
    "\n",
    "        accurary = clf.score(x_test,y_test)\n",
    "        report = classification_report(y_test,y_predict,target_names = ['drop','up'])\n",
    "        if window_length in accurarys:\n",
    "            accurarys[window_length].append(accurary)\n",
    "            reports[window_length].append(report)\n",
    "        else: \n",
    "            accurarys[window_length] = [accurary]\n",
    "            reports[window_length] = [report]\n",
    "        print('The Accurary of %s : %f'%(kernel_arg,clf.score(x_test,y_test)))\n",
    "        print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "_cell_guid": "e4ae7b8d-49ff-418a-b152-8d1e0a5b74ea",
    "_uuid": "ea65c8c0d52ba76c87f72283b730eb4a7206e8ab"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "window_length: 7\n",
      "The Accurary of rbf : 0.485194\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        drop       0.48      0.91      0.62       207\n",
      "          up       0.57      0.11      0.18       232\n",
      "\n",
      "    accuracy                           0.49       439\n",
      "   macro avg       0.52      0.51      0.40       439\n",
      "weighted avg       0.52      0.49      0.39       439\n",
      "\n",
      "The Accurary of poly : 0.478360\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        drop       0.47      0.97      0.64       207\n",
      "          up       0.59      0.04      0.08       232\n",
      "\n",
      "    accuracy                           0.48       439\n",
      "   macro avg       0.53      0.50      0.36       439\n",
      "weighted avg       0.53      0.48      0.34       439\n",
      "\n",
      "The Accurary of linear : 0.571754\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        drop       0.60      0.28      0.38       207\n",
      "          up       0.56      0.83      0.67       232\n",
      "\n",
      "    accuracy                           0.57       439\n",
      "   macro avg       0.58      0.56      0.53       439\n",
      "weighted avg       0.58      0.57      0.54       439\n",
      "\n",
      "window_length: 14\n",
      "The Accurary of rbf : 0.487414\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        drop       0.48      0.64      0.55       211\n",
      "          up       0.51      0.35      0.41       226\n",
      "\n",
      "    accuracy                           0.49       437\n",
      "   macro avg       0.49      0.49      0.48       437\n",
      "weighted avg       0.49      0.49      0.48       437\n",
      "\n",
      "The Accurary of poly : 0.478261\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        drop       0.47      0.74      0.58       211\n",
      "          up       0.49      0.23      0.31       226\n",
      "\n",
      "    accuracy                           0.48       437\n",
      "   macro avg       0.48      0.49      0.45       437\n",
      "weighted avg       0.48      0.48      0.44       437\n",
      "\n",
      "The Accurary of linear : 0.521739\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        drop       0.51      0.28      0.36       211\n",
      "          up       0.53      0.74      0.62       226\n",
      "\n",
      "    accuracy                           0.52       437\n",
      "   macro avg       0.52      0.51      0.49       437\n",
      "weighted avg       0.52      0.52      0.49       437\n",
      "\n",
      "window_length: 21\n",
      "The Accurary of rbf : 0.456422\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        drop       0.45      0.39      0.42       218\n",
      "          up       0.46      0.52      0.49       218\n",
      "\n",
      "    accuracy                           0.46       436\n",
      "   macro avg       0.46      0.46      0.45       436\n",
      "weighted avg       0.46      0.46      0.45       436\n",
      "\n",
      "The Accurary of poly : 0.486239\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        drop       0.45      0.13      0.20       218\n",
      "          up       0.49      0.84      0.62       218\n",
      "\n",
      "    accuracy                           0.49       436\n",
      "   macro avg       0.47      0.49      0.41       436\n",
      "weighted avg       0.47      0.49      0.41       436\n",
      "\n",
      "The Accurary of linear : 0.488532\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        drop       0.46      0.12      0.19       218\n",
      "          up       0.49      0.86      0.63       218\n",
      "\n",
      "    accuracy                           0.49       436\n",
      "   macro avg       0.47      0.49      0.41       436\n",
      "weighted avg       0.47      0.49      0.41       436\n",
      "\n",
      "window_length: 30\n",
      "The Accurary of rbf : 0.489607\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        drop       0.56      0.33      0.41       238\n",
      "          up       0.46      0.69      0.55       195\n",
      "\n",
      "    accuracy                           0.49       433\n",
      "   macro avg       0.51      0.51      0.48       433\n",
      "weighted avg       0.51      0.49      0.47       433\n",
      "\n",
      "The Accurary of poly : 0.457275\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        drop       0.53      0.12      0.19       238\n",
      "          up       0.45      0.87      0.59       195\n",
      "\n",
      "    accuracy                           0.46       433\n",
      "   macro avg       0.49      0.49      0.39       433\n",
      "weighted avg       0.49      0.46      0.37       433\n",
      "\n",
      "The Accurary of linear : 0.461894\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        drop       0.52      0.24      0.32       238\n",
      "          up       0.44      0.74      0.55       195\n",
      "\n",
      "    accuracy                           0.46       433\n",
      "   macro avg       0.48      0.49      0.44       433\n",
      "weighted avg       0.49      0.46      0.43       433\n",
      "\n",
      "window_length: 60\n",
      "The Accurary of rbf : 0.537559\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        drop       0.53      0.66      0.59       211\n",
      "          up       0.56      0.42      0.48       215\n",
      "\n",
      "    accuracy                           0.54       426\n",
      "   macro avg       0.54      0.54      0.53       426\n",
      "weighted avg       0.54      0.54      0.53       426\n",
      "\n",
      "The Accurary of poly : 0.539906\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        drop       0.53      0.73      0.61       211\n",
      "          up       0.57      0.35      0.43       215\n",
      "\n",
      "    accuracy                           0.54       426\n",
      "   macro avg       0.55      0.54      0.52       426\n",
      "weighted avg       0.55      0.54      0.52       426\n",
      "\n",
      "The Accurary of linear : 0.495305\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        drop       0.49      0.32      0.39       211\n",
      "          up       0.50      0.67      0.57       215\n",
      "\n",
      "    accuracy                           0.50       426\n",
      "   macro avg       0.49      0.49      0.48       426\n",
      "weighted avg       0.49      0.50      0.48       426\n",
      "\n",
      "window_length: 90\n",
      "The Accurary of rbf : 0.502392\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        drop       0.50      0.52      0.51       208\n",
      "          up       0.50      0.49      0.50       210\n",
      "\n",
      "    accuracy                           0.50       418\n",
      "   macro avg       0.50      0.50      0.50       418\n",
      "weighted avg       0.50      0.50      0.50       418\n",
      "\n",
      "The Accurary of poly : 0.485646\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        drop       0.49      0.71      0.58       208\n",
      "          up       0.48      0.27      0.34       210\n",
      "\n",
      "    accuracy                           0.49       418\n",
      "   macro avg       0.48      0.49      0.46       418\n",
      "weighted avg       0.48      0.49      0.46       418\n",
      "\n",
      "The Accurary of linear : 0.456938\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        drop       0.44      0.32      0.37       208\n",
      "          up       0.47      0.59      0.52       210\n",
      "\n",
      "    accuracy                           0.46       418\n",
      "   macro avg       0.45      0.46      0.45       418\n",
      "weighted avg       0.45      0.46      0.45       418\n",
      "\n",
      "window_length: 120\n",
      "The Accurary of rbf : 0.506083\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        drop       0.49      0.56      0.53       200\n",
      "          up       0.52      0.45      0.48       211\n",
      "\n",
      "    accuracy                           0.51       411\n",
      "   macro avg       0.51      0.51      0.51       411\n",
      "weighted avg       0.51      0.51      0.50       411\n",
      "\n",
      "The Accurary of poly : 0.486618\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        drop       0.48      0.74      0.58       200\n",
      "          up       0.50      0.25      0.33       211\n",
      "\n",
      "    accuracy                           0.49       411\n",
      "   macro avg       0.49      0.49      0.46       411\n",
      "weighted avg       0.49      0.49      0.45       411\n",
      "\n",
      "The Accurary of linear : 0.479319\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        drop       0.45      0.35      0.40       200\n",
      "          up       0.49      0.60      0.54       211\n",
      "\n",
      "    accuracy                           0.48       411\n",
      "   macro avg       0.47      0.48      0.47       411\n",
      "weighted avg       0.47      0.48      0.47       411\n",
      "\n",
      "window_length: 150\n",
      "The Accurary of rbf : 0.535980\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        drop       0.58      0.50      0.54       216\n",
      "          up       0.50      0.58      0.54       187\n",
      "\n",
      "    accuracy                           0.54       403\n",
      "   macro avg       0.54      0.54      0.54       403\n",
      "weighted avg       0.54      0.54      0.54       403\n",
      "\n",
      "The Accurary of poly : 0.526055\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        drop       0.57      0.44      0.50       216\n",
      "          up       0.49      0.62      0.55       187\n",
      "\n",
      "    accuracy                           0.53       403\n",
      "   macro avg       0.53      0.53      0.52       403\n",
      "weighted avg       0.54      0.53      0.52       403\n",
      "\n",
      "The Accurary of linear : 0.545906\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        drop       0.60      0.47      0.53       216\n",
      "          up       0.51      0.63      0.56       187\n",
      "\n",
      "    accuracy                           0.55       403\n",
      "   macro avg       0.55      0.55      0.55       403\n",
      "weighted avg       0.56      0.55      0.54       403\n",
      "\n",
      "window_length: 180\n",
      "The Accurary of rbf : 0.484848\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        drop       0.48      0.51      0.49       194\n",
      "          up       0.49      0.46      0.48       202\n",
      "\n",
      "    accuracy                           0.48       396\n",
      "   macro avg       0.49      0.49      0.48       396\n",
      "weighted avg       0.49      0.48      0.48       396\n",
      "\n",
      "The Accurary of poly : 0.489899\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        drop       0.48      0.58      0.53       194\n",
      "          up       0.50      0.40      0.45       202\n",
      "\n",
      "    accuracy                           0.49       396\n",
      "   macro avg       0.49      0.49      0.49       396\n",
      "weighted avg       0.49      0.49      0.49       396\n",
      "\n",
      "The Accurary of linear : 0.535354\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        drop       0.53      0.44      0.48       194\n",
      "          up       0.54      0.63      0.58       202\n",
      "\n",
      "    accuracy                           0.54       396\n",
      "   macro avg       0.53      0.53      0.53       396\n",
      "weighted avg       0.53      0.54      0.53       396\n",
      "\n"
     ]
    }
   ],
   "source": [
    "window_lengths = [7,14,21,30,60,90,120,150,180]\n",
    "accurarys = {}\n",
    "reports ={}\n",
    "\n",
    "for l in window_lengths:\n",
    "    print('window_length:',l)\n",
    "    train_and_test(msft_prices,l,accurarys,reports)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "fd59076a-90c3-4d8b-b413-f938641f1785",
    "_uuid": "c708e5ca843f00bd3a099ff250db65184697993b"
   },
   "source": [
    "we can see the accurary of svm is about 50%~60%\n",
    "I don't think it's a good way to predict, but as we know there is no way can predict stock market well since it was influenced by many factors which not just history price."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "d9c47339-eb37-49e0-9897-44e6de967c3c",
    "_uuid": "654c735b8f3ad6f54328b131e7e50578e7bba6a7"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}